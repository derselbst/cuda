\chapter{Einleitung / Aufgabenstellung}
Die Herstellung komplexer und hochintegrierter mikroelektronischer Schaltkreise stellt höchste Anforderungen an die Geräte,
% und Maschinen
die zu deren Herstellung eingesetzt werden.
Während des gesamten Produktionsprozesses müssen sehr hohe Qualitätsstandards eingehalten werden.
Es ist davon auszugehen, dass die Integrationsdichte integrierter Schaltungen immer größer werden wird, d.h. es müssen immer feinere Strukturen auf einer Fläche abgebildet werden.
\\\\
Die {\betrieb} ist ein führender Ausstatter der Halbleiterindustrie.
Zum Portfolio gehören unter anderem Photomaskensysteme, welche im Herstellungsprozess von hochintegrierten Schaltkreisen eingesetzt werden.
\\\\
Damit ZEISS als wichtiger Partner der Halbleiterindustrie auch weiterhin hochwertige Produkte an seine Kunden ausliefern kann, bedarf es im Vorfeld intensiver Produkttests und im Nachgang ständiger Unterstützung des Kunden bei der Wartung dieser Photomaskensysteme.
\\\\
%reihenfolge beachten zuerst aimseuv
Der Service--Mitarbeiter muss in die Lage versetzt werden, bei einem solch komplexen System
%, und im vorliegenden Fall der zugehörigen Wasserkühlung, 
einen schnellen und präzisen Überblick über die Baugruppen und Module zu erhalten.
Dazu ist es notwendig, dass ihm zur Unterstützung bei seiner Arbeit ein entsprechendes Werkzeug zur Verfügung gestellt wird.
Die Herausforderung bei solchen Service- und Diagnose--Anwendungen besteht darin, eine einfache und übersichtliche Darstellung zur Fehlererkennung und -lokalisierung bereitzustellen. Andererseits müssen komplexe und spezifische Informationen über jeden Teil der Komponente erfasst sein.
\\\\
Im Rahmen dieser {\arbeit} soll die Entwicklung einer \textbf{apfelsaftpresse} vorgestellt werden, die Hilfestellung bei der Errichtung und Wartung der Wasserkühlung für das {\aimseuv} bietet.


\chapter{Grundlagen}
 
geg: datensätze: ergebnisse der abtastung von oberflächen in der elektronen mikroskopie


jeder datensatz enthält für eine x und y position (i.e. position auf der oberfläche) die höhe der abgetasteten fläche und die der abtastspitze entgegengebrachte kraft

es existieren 256 x 256 datensätze, also 65536 datensätze mit je ca. 600 messwerten, d.h. 2*300 Messwerte für einen absenkteil und zurückzieher teil.

messwerte jedes datensatzes ergeben kurve

           /
          /
----\    /
     \  /
      \/
% ^
 annäherung der probe
 %      ^
       kontakt punkt (adhäsionskräfte)
 %        ^ entgegengebrachte kraft
         
gegebenen datenpunkte sind mittels polyfit  in drei lineare zu approximieren. anschließend anhand der drei approximierten funktionen: bestimmung: kontaktpunkt, ansteig kurve entgegenbebrachte kraft, split index

herangehensweise: 

\section{parsen der daten}
daten liegen als csv dateien vor, deren messwerte spalten und zeilenweise gespeichert sind. diese 100KB kleinen textdateien einlesen und verarbeiten.
problem: hoher overhead seitens des OS aufgrund häufigem öffnen / schliessen der dateien. dateien sind klein und nur ca. 1/10 des inhalts wird tatsächlich genutzt, der rest wird ignoriert, da nicht relevant --> erschwert caching dur das OS.

\section{parallelisierungsmodell}
aufgrund der hohen anzahl an datensätzen: naive parallelisierung: jeder thread der graka bearbeitet einen datensatz. konkret:
- gegebene punktwolke ableiten um den kontaktpunkt zu bestimmen
- polyfit der kurve nach kontakt mit medium durchführen
- ermittlung des split index
- polyfit der kurven vor und nach dem split index durchführen

\section{datenmodell}
einlesen der daten als AoS:

\begin{lstlisting}
struct tuple_t { float z,f; };
tuple_t datasets[M][N];
\end{lstlisting}

N: anzahl an datensätze
M: anzahl an messwerten pro datensatz

für grafikkarten ungeeignet, da daten für die einzelene threads zu weit auseinander liegen. caching wird unmöglich, schlimmsten falls führt dies zu einer ausserialisierung der threads.

daher: datensätze columnmajor im speicher ablegen:

\begin{lstlisting}
struct tuple_t { float z,f; };
tuple_t datasets[N][M];
\end{lstlisting}

jeder thread bearbeitet einen datensatz. daher sieht es für jeden thread so aus, als handle es sich bei datasets um ein SoA. d.h. beim ersten zugriff auf datasets liest jeder thread die erste messreihe seines datensatzes ein, beim zweiten zugriff die zweite messreihe, etc.

\subsection{optimiertes datenmodell}
optimalerweise erhält jeder thread durch einen lesevorgang ein 4 byte wort aus der cacheline. tuple_t hat jedoch eine größe von 8bytes. es braucht als zwei lesevorgänge um alle threads eines warps??? mit daten zu versorgen.
daher folgende optimierung:

\begin{lstlisting}
struct tuple_t { float z[N],f[N]; };
tuple_t datasets[M];
\end{lstlisting}

nun ist tuple_t ein reines soa welches M mal existiert und jeweils zeiger auf arrays enthält, die die z und force messwerte der N datensätze enthält. diese können somit von N threads single strided bearbeitet werden:

\begin{lstlisting}
tuple_t datasets[M];
extern int threadId;

for (i=0; i<M; i++)
{
    float myZ = datasets[i].z[threadId];
    float myForce = datasets[i].f[threadId];
    
    // doWork(myZ, myForce);
}
\end{lstlisting}

\chapter{benchmarking}
\section{lesen der textdateien}
von konventioneller HDD: 8MiB/s
von SSD:  35 MiB/s -O0
70 MiB/s -O2
41 s bei 190 MiB/s -O2 paralleles lesen mit openmp tasks

referenz implementierung 11 MiB/s von SSD

referenz implementierung 11 minuten insgesamt
